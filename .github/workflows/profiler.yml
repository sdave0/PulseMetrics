name: Pipeline Profiler
on:
  workflow_run:
    workflows: ["CI/CD Pipeline"]
    types:
      - completed

permissions:
  actions: read
  contents: write

jobs:
  profile:
    runs-on: ubuntu-latest
    steps:
      - name: Download, Analyze, and Summarize
        id: analyze_step
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const { execSync } = require('child_process');

            // --- 1. GATHER DATA ---
            const workflowRun = (await github.rest.actions.getWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.payload.workflow_run.id,
            })).data;

            const jobs = (await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.payload.workflow_run.id,
            })).data.jobs;

            const allArtifacts = (await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.payload.workflow_run.id,
            })).data.artifacts;

            // --- 2. DOWNLOAD AND EXTRACT ARTIFACTS ---
            for (const artifact of allArtifacts) {
              console.log(`Downloading artifact: ${artifact.name}`);
              try {
                const download = await github.rest.actions.downloadArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: artifact.id,
                  archive_format: 'zip',
                });
                fs.writeFileSync(`${artifact.name}.zip`, Buffer.from(download.data));
                console.log(`Downloaded: ${artifact.name}.zip`);
              } catch (error) {
                console.log(`Failed to download ${artifact.name}: ${error.message}`);
              }
            }

            execSync('mkdir -p dist');
            if (fs.existsSync('build-artifacts.zip')) { execSync('unzip -o build-artifacts.zip -d dist/'); }
            if (fs.existsSync('test-results.zip')) { execSync('unzip -o test-results.zip'); }
            if (fs.existsSync('build-log.zip')) { execSync('unzip -o build-log.zip'); }

            // --- 3. PROCESS DATA & ASSEMBLE JSON PAYLOAD ---
            let payload = {};

            // Workflow Info
            payload.workflow = {
              run_id: workflowRun.id,
              run_number: workflowRun.run_number,
              name: workflowRun.name,
              html_url: workflowRun.html_url,
              status: workflowRun.conclusion,
              trigger: workflowRun.event,
              branch: workflowRun.head_branch,
              duration_seconds: Math.round((new Date(workflowRun.updated_at).getTime() - new Date(workflowRun.created_at).getTime()) / 1000),
              created_at: workflowRun.created_at,
              completed_at: workflowRun.updated_at,
            };

            // Commit Info
            if (workflowRun.head_commit) {
              payload.commit = {
                sha: workflowRun.head_commit.id,
                message: workflowRun.head_commit.message,
                author: workflowRun.head_commit.author.name,
              };
            }

            // Job Info
            payload.jobs = jobs.map(job => ({
              name: job.name,
              status: job.conclusion,
              duration_seconds: job.completed_at && job.started_at ? Math.round((new Date(job.completed_at).getTime() - new Date(job.started_at).getTime()) / 1000) : 0,
            }));

            // Test Summary
            try {
              const testData = JSON.parse(fs.readFileSync('test-results.json', 'utf8'));
              payload.test_summary = {
                passed: testData.numPassedTests || 0,
                failed: testData.numFailedTests || 0,
                total: testData.numTotalTests || 0,
                suites: testData.numTotalTestSuites || 0,
              };
            } catch { payload.test_summary = null; }

            // Build Analysis
            try {
              const buildLog = fs.readFileSync('build-log.txt', 'utf8');
              let cache_status = 'Unknown';
              if (buildLog.includes('cache hit') || buildLog.includes('Cache hit')) { cache_status = 'Hit'; }
              else if (buildLog.includes('cache miss') || buildLog.includes('Cache miss')) { cache_status = 'Miss'; }
              
              const buildSize = execSync('du -sk dist/ 2>/dev/null || echo "0"').toString().trim().split('\t')[0];

              payload.build_analysis = {
                cache_status: cache_status,
                build_size_kb: parseInt(buildSize, 10),
              };
            } catch { payload.build_analysis = null; }

            // Artifacts Info
            payload.artifacts = allArtifacts.map(artifact => ({
              name: artifact.name,
              size_kb: Math.round(artifact.size_in_bytes / 1024),
            }));

            // --- 4. SET OUTPUTS ---
            const jsonPayload = JSON.stringify(payload, null, 2);
            core.setOutput('summary_data', jsonPayload);

            // Also write a nice summary to the GitHub UI
            await core.summary
              .addHeading('Workflow Metrics Summary')
              .addCodeBlock(jsonPayload, 'json')
              .write();

            console.log('Successfully generated JSON metrics payload.');

      - name: Send Summary to Webhook
        if: success()
        env:
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
        run: |
          echo '${{ steps.analyze_step.outputs.summary_data }}' > payload.json
          curl -X POST -H "Content-Type: application/json" --data @payload.json "$WEBHOOK_URL"